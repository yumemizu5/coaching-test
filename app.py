# st.session_stateã‚’ä½¿ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚„ã‚Šã¨ã‚Šã‚’ä¿å­˜
# if "messages" not in st.session_state:
# st.session_state["messages"] = [
# {"role": "system", "content": system_prompt}
# ]

# # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
# def communicate():
# messages = st.session_state["messages"]

# user_message = {"role": "user", "content": st.session_state["user_input"]}
# messages.append(user_message)

# response = openai. ChatCompletion.create(
# model="gpt-3.5-turbo",
# messages=messages
# )

# bot_message = response["choices"][0]["message"]
# messages.append(bot_message)

# st.session_state["user_input"] = "" # å…¥åŠ›æ¬„ã‚’æ¶ˆå»

# # ãƒœãƒƒãƒˆã®å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’éŸ³å£°ã«å¤‰æ›
# tts = gTTS(bot_message["content"], lang='ja') # æ—¥æœ¬èªå¯¾å¿œ
# tts_file = BytesIO()
# tts.save(tts_file)
# tts_file.seek(0)

# # éŸ³å£°å†ç”Ÿï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®šï¼‰
# st.audio(tts_file, format='audio/mp3')

# # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã®æ§‹ç¯‰
# st.title("ã€Œã¿ãˆAiã€ã‚³ãƒ¼ãƒãƒ³ã‚°ãƒœãƒƒãƒˆ")
# st.image("mieai.png")
# st.write("æ‚©ã¿äº‹ã¯ä½•ã§ã™ã‹ï¼Ÿ")

# user_input = st.text_input("æ‚©ã¿äº‹ã‚’ä¸‹ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", key="user_input", on_change=communicate)

# if st.session_state["messages"]:
# messages = st.session_state["messages"]

# for message in reversed(messages[1:]): # ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸Šã«
# speaker = "ğŸ™‚"
# if message["role"] == "assistant":
# speaker = "ğŸ¤–"

# st.write(speaker + ": " + message["content"])

# else:
# # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã‚‹å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
# st.write("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã«æ­£ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚" )

ã“ã®ã‚³ãƒ¼ãƒ‰ã§ç”Ÿæˆã•ã‚Œã‚‹Chatgptã‹ã‚‰ã®è¿”ç­”ã‚’éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã—ã¦ãã ã•ã„
